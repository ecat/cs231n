{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pkllee/anaconda2/envs/tf/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('loading scan ', 4)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import dataset as dd # custom dataset class\n",
    "\n",
    "# so that when you change an imported file, it changes in the notebook\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "\n",
    "# Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n",
    "try:\n",
    "   del X_train, y_train\n",
    "   del X_test, y_test\n",
    "   print('Clear previously loaded data.')\n",
    "except:\n",
    "   pass\n",
    "\n",
    "#im_ref, im_us = dd.get_dataset(1)\n",
    "#im_us_aug = dd.augment_channel_image(im_us)\n",
    "#X_train, y_train = (im_us_aug,  im_ref)\n",
    "#X_train, y_train = (im_us,  im_ref)\n",
    "\n",
    "do_channel_augmentation = True\n",
    "im_ref_test, im_us_test = dd.get_dataset(4)\n",
    "\n",
    "if(do_channel_augmentation == True):\n",
    "    im_us_test_aug = dd.augment_channel_image(im_us_test)\n",
    "    X_test, y_test = (im_us_test_aug, im_ref_test)\n",
    "else:\n",
    "    X_test, y_test = (im_us_test, im_ref_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test data shape: ', (320, 320, 256, 16))\n",
      "('Test labels shape: ', (320, 320, 256, 1))\n"
     ]
    }
   ],
   "source": [
    "#print('Training data shape: ', X_train.shape)\n",
    "#print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unetblocks import res_block, gen_conv_relu, gen_conv_bn_relu\n",
    "\n",
    "input_shape = X_test.shape[1:]\n",
    "inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "gen_conv_params = lambda num_filters : {'filters': num_filters, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'same'}\n",
    "f16 = gen_conv_params(16)\n",
    "f32 = gen_conv_params(32)\n",
    "f64 = gen_conv_params(64)\n",
    "f128 = gen_conv_params(128)\n",
    "f256 = gen_conv_params(256)\n",
    "f512 = gen_conv_params(512)\n",
    "f1024 = gen_conv_params(1024)\n",
    "\n",
    "#gen_fn = gen_conv_bn_relu\n",
    "gen_fn = gen_conv_relu\n",
    "\n",
    "# very small unet no pooling\n",
    "'''\n",
    "res_out = res_block(gen_fn(N=2, **f16), gen_fn(N=2, **f16), use_pool=False)(inputs, \n",
    "                                                      resblocks=[res_block(gen_fn(N=3, **f32))])\n",
    "'''\n",
    "# very small unet with pooling\n",
    "\n",
    "res_out = res_block(gen_fn(N=2, **f16), gen_fn(N=2, **f16))(inputs, \n",
    "                                                      resblocks=[res_block(gen_fn(N=3, **f32))])\n",
    "\n",
    "# small unet\n",
    "'''\n",
    "res_out = res_block(gen_fn(N=2, **f16), gen_fn(N=2, **f16))(inputs, \n",
    "                                                      resblocks=[res_block(gen_fn(N=3, **f32), gen_fn(N=3, **f32)),\n",
    "                                                                 res_block(gen_fn(N=3, **f64), gen_fn(N=3, **f64)),\n",
    "                                                                         res_block(gen_fn(N=3, **f128))])\n",
    "'''\n",
    "\n",
    "# big unet\n",
    "'''\n",
    "res_out = res_block(gen_fn(N=2, **f32), gen_fn(N=2, **f32))(inputs, \n",
    "                                                      resblocks=[res_block(gen_fn(N=2, **f64), gen_fn(N=2, **f64)),\n",
    "                                                                 res_block(gen_fn(N=2, **f128), gen_fn(N=2, **f128)),\n",
    "                                                                 res_block(gen_fn(N=2, **f256), gen_fn(N=2, **f256)),\n",
    "                                                                         res_block(gen_fn(N=2, **f512))])\n",
    "'''\n",
    "\n",
    "out = tf.keras.layers.Dense(1)(res_out)\n",
    "model = tf.keras.models.Model(inputs=inputs, outputs=out)\n",
    "## example from https://keras.io/callbacks/\n",
    "class LossHistory(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, test_data = None):\n",
    "        self.test_data = test_data\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.train_losses_batch = []\n",
    "        self.train_losses_epoch = []\n",
    "        self.test_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.train_losses_batch.append(logs.get('loss'))\n",
    "        \n",
    "    def on_epoch_end(self, epochs, logs={}):\n",
    "        self.train_losses_epoch.append(logs.get('loss'))\n",
    "        \n",
    "        if (epochs % 10 == 0 and self.test_data != None):\n",
    "            x, y = self.test_data\n",
    "            loss, _ = self.model.evaluate(x, y, verbose=0)\n",
    "            self.test_losses.append(loss)\n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "history_callback = LossHistory(test_data=(X_test, y_test))\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir='/home/pkllee/tmp/')\n",
    "\n",
    "#adam_optimizer = tf.keras.optimizers.Adam(lr=0.1, beta_1 = 0.9, beta_2=0.999, decay=0.1)\n",
    "adam_optimizer = tf.keras.optimizers.Adam(lr=0.001, decay=0.01)\n",
    "\n",
    "model.compile(optimizer=adam_optimizer, loss='mean_squared_error', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 320, 256, 16) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 320, 256, 16) 2320        input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 320, 256, 16) 0           conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 320, 256, 16) 2320        activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 320, 256, 16) 0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 160, 128, 16) 0           activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 160, 128, 32) 4640        max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 160, 128, 32) 0           conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 160, 128, 32) 9248        activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 160, 128, 32) 0           conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 160, 128, 32) 9248        activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 160, 128, 32) 0           conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2D)  (None, 320, 256, 32) 0           activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 320, 256, 48) 0           up_sampling2d_9[0][0]            \n",
      "                                                                 input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 320, 256, 16) 6928        concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 320, 256, 16) 0           conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 320, 256, 16) 2320        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 320, 256, 16) 0           conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 320, 256, 1)  17          activation_63[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 37,041\n",
      "Trainable params: 37,041\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('loading scan ', 1)\n",
      "('X shape: ', (320, 320, 256, 16))\n",
      "('y shape: ', (320, 320, 256, 1))\n",
      "('loading scan ', 2)\n",
      "('X shape: ', (320, 320, 256, 16))\n",
      "('y shape: ', (320, 320, 256, 1))\n",
      "('loading scan ', 3)\n",
      "('X shape: ', (320, 320, 256, 16))\n",
      "('y shape: ', (320, 320, 256, 1))\n"
     ]
    }
   ],
   "source": [
    "generator =  dd.MRImageSequence(scan_numbers=[1, 2, 3], batch_size=10, augment_channels=do_channel_augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "(2, 40, 50)\n",
      "(2, 60, 70)\n",
      "(1, 60, 70)\n",
      " 2/96 [..............................] - ETA: 2:02 - loss: 0.0058 - mean_squared_error: 0.0058(0, 190, 200)\n",
      " 3/96 [..............................] - ETA: 1:54 - loss: 0.0060 - mean_squared_error: 0.0060(2, 130, 140)\n",
      " 4/96 [>.............................] - ETA: 1:46 - loss: 0.0055 - mean_squared_error: 0.0055(0, 180, 190)\n",
      " 5/96 [>.............................] - ETA: 1:36 - loss: 0.0052 - mean_squared_error: 0.0052(2, 110, 120)\n",
      " 6/96 [>.............................] - ETA: 1:30 - loss: 0.0048 - mean_squared_error: 0.0048(1, 120, 130)\n",
      " 7/96 [=>............................] - ETA: 1:25 - loss: 0.0044 - mean_squared_error: 0.0044(0, 0, 10)\n",
      " 8/96 [=>............................] - ETA: 1:21 - loss: 0.0043 - mean_squared_error: 0.0043(1, 40, 50)\n",
      " 9/96 [=>............................] - ETA: 1:17 - loss: 0.0041 - mean_squared_error: 0.0041(0, 70, 80)\n",
      "10/96 [==>...........................] - ETA: 1:14 - loss: 0.0038 - mean_squared_error: 0.0038(0, 300, 310)\n",
      "11/96 [==>...........................] - ETA: 1:11 - loss: 0.0035 - mean_squared_error: 0.0035(0, 210, 220)\n",
      "12/96 [==>...........................] - ETA: 1:11 - loss: 0.0033 - mean_squared_error: 0.0033(2, 120, 130)\n",
      "13/96 [===>..........................] - ETA: 1:09 - loss: 0.0031 - mean_squared_error: 0.0031(0, 240, 250)\n",
      "14/96 [===>..........................] - ETA: 1:07 - loss: 0.0031 - mean_squared_error: 0.0031(1, 130, 140)\n",
      "15/96 [===>..........................] - ETA: 1:05 - loss: 0.0029 - mean_squared_error: 0.0029(1, 240, 250)\n",
      "16/96 [====>.........................] - ETA: 1:04 - loss: 0.0030 - mean_squared_error: 0.0030(0, 110, 120)\n",
      "17/96 [====>.........................] - ETA: 1:02 - loss: 0.0031 - mean_squared_error: 0.0031(0, 250, 260)\n",
      "18/96 [====>.........................] - ETA: 1:01 - loss: 0.0030 - mean_squared_error: 0.0030(2, 80, 90)\n",
      "19/96 [====>.........................] - ETA: 59s - loss: 0.0029 - mean_squared_error: 0.0029 (2, 290, 300)\n",
      "20/96 [=====>........................] - ETA: 58s - loss: 0.0028 - mean_squared_error: 0.0028"
     ]
    }
   ],
   "source": [
    "#model.fit(x=X_train, y=y_train, callbacks=[history_callback, tb_callback], epochs=100, batch_size=10)\n",
    "\n",
    "model.fit_generator(generator, callbacks=[history_callback, tb_callback], epochs=1, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.log10(history_callback.train_losses_epoch))\n",
    "plt.title('train log loss')\n",
    "plt.xlabel('Batch Number')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.log10(history_callback.test_losses))\n",
    "plt.title('test log loss')\n",
    "plt.xlabel('10 epochs')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict(X_test)\n",
    "to_show_ref_test = y_test\n",
    "to_show_us_test = X_test\n",
    "\n",
    "pred_train = model.predict(generator.x_ref)\n",
    "to_show_ref_train  = generator.y_ref\n",
    "to_show_us_train = generator.x_ref\n",
    "\n",
    "#mean_squared_error = tf.keras.losses.mean_squared_error(pred_test, to_show_ref_test)\n",
    "#print(mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(slice_to_show, pred, ref, us):\n",
    "    im1 = pred[slice_to_show, :, :, 0]    \n",
    "    im2 = ref[slice_to_show, :, :, 0]\n",
    "    im3 = dd.sos(us[slice_to_show, :, :, :], axis=2)\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(np.hstack((im1, im2, im3)), cmap='gray')\n",
    "    plt.title('pred | ref | us')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(abs(im2 - im1)* 10, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.title('diff x10')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_to_show = 130\n",
    "show_images(slice_to_show, pred_test, to_show_ref_test, to_show_us_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(slice_to_show, pred_train, to_show_ref_train, to_show_us_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('models/very_small_unet_no_aug_kernel_1_3_no_pooling.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

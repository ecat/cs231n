{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pkllee/anaconda2/envs/tf/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import dataset as dd # custom dataset class\n",
    "import models as md\n",
    "\n",
    "# so that when you change an imported file, it changes in the notebook\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('loading scan ', 1)\n",
      "('X shape: ', (320, 320, 256, 16))\n",
      "('y shape: ', (320, 320, 256, 1))\n",
      "('augment_images: ', False)\n",
      "('loading scan ', 5)\n",
      "('X shape: ', (320, 320, 256, 16))\n",
      "('y shape: ', (320, 320, 256, 1))\n",
      "('augment_images: ', False)\n"
     ]
    }
   ],
   "source": [
    "do_channel_augmentation = True\n",
    "epochs_to_train = 100\n",
    "\n",
    "# use this to train on multiple datasets with data augmentation\n",
    "#generator_train =  dd.MRImageSequence(scan_numbers=[1, 2, 3, 4], batch_size=10, augment_channels=do_channel_augmentation, augment_images=True)\n",
    "\n",
    "# use this to train on a single knee (makai)\n",
    "generator_train =  dd.MRImageSequence(scan_numbers=[1], batch_size=10, augment_channels=do_channel_augmentation)\n",
    "\n",
    "generator_test = dd.MRImageSequence(scan_numbers=[5], batch_size=10, augment_channels=do_channel_augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_unet\n",
      "('use_pool: ', True)\n",
      "('gen_fn: ', 'gen_conv_relu')\n",
      "('unet_shape: ', [(2, 32), (3, 64)])\n"
     ]
    }
   ],
   "source": [
    "input_shape = generator_train.x_transformed[0].shape[1:]\n",
    "inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "\n",
    "#out = md.get_very_small_unet(inputs, use_pool=True)\n",
    "out = md.get_unet(inputs, [(2, 32), (3, 64)], use_pool=True)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=inputs, outputs=out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## example from https://keras.io/callbacks/\n",
    "class LossHistory(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, test_data = None):\n",
    "        self.test_data = test_data\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.train_losses_batch = []\n",
    "        self.train_losses_epoch = []\n",
    "        self.test_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.train_losses_batch.append(logs.get('loss'))\n",
    "        \n",
    "    def on_epoch_end(self, epochs, logs={}):\n",
    "        self.train_losses_epoch.append(logs.get('loss'))\n",
    "        \n",
    "        if (epochs % 10 == 0 and self.test_data != None):\n",
    "            x, y = self.test_data\n",
    "            loss, _ = self.model.evaluate(x, y, verbose=0)\n",
    "            self.test_losses.append(loss)\n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "history_callback = LossHistory(test_data=(generator_test.x_transformed[0], generator_test.y_transformed[0]))\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir='/home/pkllee/tmp/')\n",
    "\n",
    "adam_optimizer = tf.keras.optimizers.Adam(lr=0.001, decay=0.01)\n",
    "\n",
    "model.compile(optimizer=adam_optimizer, loss='mean_squared_error', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 320, 256, 16) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 320, 256, 32) 4640        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 320, 256, 32) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 320, 256, 32) 9248        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 320, 256, 32) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 160, 128, 32) 0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 160, 128, 64) 18496       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 160, 128, 64) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 160, 128, 64) 36928       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 160, 128, 64) 0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 160, 128, 64) 36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 160, 128, 64) 0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 320, 256, 64) 0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 320, 256, 80) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 320, 256, 32) 23072       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 320, 256, 32) 0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 320, 256, 32) 9248        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 320, 256, 32) 0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 320, 256, 1)  33          activation_7[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 138,593\n",
      "Trainable params: 138,593\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 36s 1s/step - loss: 4.2837e-04 - mean_squared_error: 4.2837e-04\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 20s 631ms/step - loss: 1.4203e-04 - mean_squared_error: 1.4203e-04\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 19s 594ms/step - loss: 1.0058e-04 - mean_squared_error: 1.0058e-04\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 18s 562ms/step - loss: 7.9982e-05 - mean_squared_error: 7.9982e-05\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 19s 579ms/step - loss: 6.8023e-05 - mean_squared_error: 6.8023e-05\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 18s 567ms/step - loss: 6.0508e-05 - mean_squared_error: 6.0508e-05\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 16s 511ms/step - loss: 5.3213e-05 - mean_squared_error: 5.3213e-05\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 16s 498ms/step - loss: 4.7511e-05 - mean_squared_error: 4.7511e-05\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 17s 537ms/step - loss: 4.4220e-05 - mean_squared_error: 4.4220e-05\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 18s 568ms/step - loss: 4.0663e-05 - mean_squared_error: 4.0663e-05\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 29s 905ms/step - loss: 3.7822e-05 - mean_squared_error: 3.7822e-05\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 17s 529ms/step - loss: 3.6115e-05 - mean_squared_error: 3.6115e-05\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 3.6555e-05 - mean_squared_error: 3.6555e-05\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 15s 456ms/step - loss: 3.5039e-05 - mean_squared_error: 3.5039e-05\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 3.4820e-05 - mean_squared_error: 3.4820e-05\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 17s 541ms/step - loss: 3.2126e-05 - mean_squared_error: 3.2126e-05\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 17s 538ms/step - loss: 3.1003e-05 - mean_squared_error: 3.1003e-05\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 18s 560ms/step - loss: 3.0599e-05 - mean_squared_error: 3.0599e-05\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 17s 535ms/step - loss: 3.0303e-05 - mean_squared_error: 3.0303e-05\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 18s 551ms/step - loss: 2.9829e-05 - mean_squared_error: 2.9829e-05\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 30s 928ms/step - loss: 2.9030e-05 - mean_squared_error: 2.9030e-05\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 18s 548ms/step - loss: 2.9435e-05 - mean_squared_error: 2.9435e-05\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 18s 560ms/step - loss: 2.8652e-05 - mean_squared_error: 2.8652e-05\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 16s 513ms/step - loss: 2.8311e-05 - mean_squared_error: 2.8311e-05\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 18s 554ms/step - loss: 2.7093e-05 - mean_squared_error: 2.7093e-05\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 18s 550ms/step - loss: 2.7496e-05 - mean_squared_error: 2.7496e-05\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 18s 572ms/step - loss: 2.7037e-05 - mean_squared_error: 2.7037e-05\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 2.7348e-05 - mean_squared_error: 2.7348e-05\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 18s 563ms/step - loss: 2.6365e-05 - mean_squared_error: 2.6365e-05\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 18s 560ms/step - loss: 2.5871e-05 - mean_squared_error: 2.5871e-05\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 31s 956ms/step - loss: 2.5623e-05 - mean_squared_error: 2.5623e-05\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 19s 587ms/step - loss: 2.5466e-05 - mean_squared_error: 2.5466e-05\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 18s 577ms/step - loss: 2.5025e-05 - mean_squared_error: 2.5025e-05\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 19s 589ms/step - loss: 2.5081e-05 - mean_squared_error: 2.5081e-05\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 18s 549ms/step - loss: 2.4822e-05 - mean_squared_error: 2.4822e-05\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 18s 572ms/step - loss: 2.4612e-05 - mean_squared_error: 2.4612e-05\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 18s 553ms/step - loss: 2.4305e-05 - mean_squared_error: 2.4305e-05\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 17s 516ms/step - loss: 2.4199e-05 - mean_squared_error: 2.4199e-05\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 17s 541ms/step - loss: 2.4166e-05 - mean_squared_error: 2.4166e-05\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 19s 583ms/step - loss: 2.4121e-05 - mean_squared_error: 2.4121e-05\n",
      "Epoch 41/100\n",
      "31/32 [============================>.] - ETA: 0s - loss: 2.4031e-05 - mean_squared_error: 2.4031e-05"
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator_train, callbacks=[history_callback, tb_callback], epochs=epochs_to_train, \n",
    "                    use_multiprocessing=False) # use_multiprocessing=True is slower by about 50% compared to model.fit() so set it to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.log10(history_callback.train_losses_epoch))\n",
    "plt.title('train log loss')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.log10(history_callback.test_losses))\n",
    "plt.title('test log loss')\n",
    "plt.xlabel('10 epochs')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict(generator_test.x_transformed[0])\n",
    "to_show_ref_test = generator_test.y_transformed[0]\n",
    "to_show_us_test = generator_test.x_transformed[0]\n",
    "\n",
    "pred_train = model.predict(generator_train.x_transformed[0])\n",
    "to_show_ref_train  = generator_train.y_transformed[0]\n",
    "to_show_us_train = generator_train.x_transformed[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(slice_to_show, pred, ref, us):\n",
    "    im1 = pred[slice_to_show, :, :, 0]    \n",
    "    im2 = ref[slice_to_show, :, :, 0]\n",
    "    im3 = dd.sos(us[slice_to_show, :, :, :], axis=2)\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(np.hstack((im1, im2, im3)), cmap='gray')\n",
    "    plt.title('pred | ref | us')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(abs(im2 - im1)* 10, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.title('diff x10')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_to_show = 100\n",
    "show_images(slice_to_show, pred_test, to_show_ref_test, to_show_us_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(slice_to_show, pred_train, to_show_ref_train, to_show_us_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('models/very_small_unet_no_aug_kernel_1_3_no_pooling.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
